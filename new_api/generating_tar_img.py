from pathlib import Path
from openai import OpenAI
import yaml

from google import genai
from google.genai import types
import pandas as pd

# ì§€ì¹¨ ë¶ˆëŸ¬ì˜¤ê¸°(.txt)
guide_path = Path(__file__).resolve().parent / "prompting_guide.txt"
system_instructions = guide_path.read_text(encoding="utf-8")
cfg_path = Path("config.yaml")
info = yaml.safe_load(cfg_path.read_text(encoding="utf-8"))

def save_images(response, name: str, out_dir: Path) -> list[Path]:
    out_dir.mkdir(parents=True, exist_ok=True)
    saved = []
    idx = 0

    # ì‘ë‹µì˜ partë“¤ ì¤‘ inline_dataê°€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. :contentReference[oaicite:1]{index=1}
    def handle_parts(parts):
        nonlocal idx
        for part in parts or []:
            if getattr(part, "inline_data", None):
                img = part.as_image()
                out_path = out_dir / f"{name}_tgt{idx:02d}.png"  # ì €ì¥í•  ìƒì„± ì´ë¯¸ì§€ ì´ë¦„
                img.save(out_path)
                saved.append(out_path)
                idx += 1

    candidates = getattr(response, "candidates", None) or []
    print("batch :",candidates)
    if candidates:
        for cand in candidates:
            content = getattr(cand, "content", None)
            handle_parts(getattr(content, "parts", None))
    else:
        handle_parts(getattr(response, "parts", None))

    # í…ìŠ¤íŠ¸ë§Œ ì˜¤ëŠ” ê²½ìš°(responseì— ì´ë¯¸ì§€ ì—†ì„ ë•Œ)
    if not saved and getattr(response, "text", None):
        (out_dir / f"{name}_response_text.txt").write_text(response.text, encoding="utf-8")

    return saved

def call_gpt(mykey: str, user_prompt: str) -> str:
    client = OpenAI(api_key=mykey)
    final_user_content = (
        f"{user_prompt}\n\n"
        "ì´ì œ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê±°ì—ì„œ ë‚´ ì§€ì¹¨ì— ë§ëŠ” ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì¤˜."
    )
    response = client.responses.create(
        model=info["gpt"]["model"],
        temperature = 0.8,
        input=[
            {"role": "system", "content": system_instructions},
            {"role": "user", "content": final_user_content},
        ],
    )
    return response.output_text

def call_gemini(mykey, ref_img, prompt):
    client = genai.Client(api_key=mykey)

    # ì´ë¯¸ì§€ íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ Partë¡œ ê°ì‹¸ê¸°
    img_bytes = Path(ref_img).read_bytes()
    img_part = types.Part.from_bytes(data=img_bytes, mime_type="image/png")
    # input
    contents = [
        "Reference Image (STRICT): Use this as the visual reference.",
        img_part,
        prompt,
    ]
    # gemini í˜¸ì¶œ
    response = client.models.generate_content(
        model=info["gemini"]["model"],
        temperature = 0.8,
        contents=contents,
        config=types.GenerateContentConfig(
            candidate_count=info["gemini"]["batch"],
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(
                aspect_ratio=info["gemini"]["aspect_ratio"],
                image_size=info["gemini"]["image_size"],
            ),
        ),
    )

    out_dir = Path(info["output"]["output_dir"])
    img_file_name = Path(ref_img).stem
    saved = save_images(response, img_file_name, out_dir) # out_dir / img_file_name
    return saved

def main():
    gpt_key = info["gpt"]["key"]
    df = pd.read_csv("data.csv") # íŒŒì¼ ë°›ê¸°
    # í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    user_prompt = df["col1"].tolist()
    # ë ˆí¼ëŸ°ìŠ¤ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    input_ref = df["col2"].tolist()
    user_prompt = list() # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸.
    input_ref = list() # ì—¬ê¸°ì— ë„£ì„ reference ì´ë¯¸ì§€ ê²½ë¡œ
    for user in user_prompt:
        for input_img in input_ref:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±(geminiì— ë„£ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±)
            gen_prompt = call_gpt(gpt_key, user)
            print("ğŸ“·reference imageğŸ“·")
            print(input_img)
            print("âœ…ìƒì„±ëœ í”„ë¡¬í”„íŠ¸âœ…")
            print(gen_prompt)
            print()

            # ì œë¯¸ë‚˜ì´ ì´ë¯¸ì§€ ìƒì„±
            gemini_key = info["gemini"]["key"]
            saved_img = call_gemini(gemini_key, input_img, gen_prompt)

            print(f'ğŸ¤–Model: {info["gemini"]["model"]}')
            print(f'ğŸ“ŠOutput: {Path(info["output"]["output_dir"]).resolve()}')
            for p in saved_img:
                print(f"ğŸ’¾Saved:  {p.resolve()}")
            print("--------------------------------------------------")

if __name__ == "__main__":
    main()
